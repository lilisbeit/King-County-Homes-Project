{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# King County House Sales Analysis\n",
    "\n",
    "**Author:** Lili Beit\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "A large real estate firm in the Seattle area is seeking to maximize prices for home sellers.  My task is to use data from previous home sales to predict future prices.  The firm aims to cast a wide net and attract clients at all price points from throughout the county."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "The real estate firm operates throughout King County, which includes the metropolis of Seattle, as well as suburban and rural areas.  Home prices vary greatly between these diverse landscapes, as well as between neighborhoods in Seattle.  The firm needs to accurately price a home based on data such as its size, location, and number of bedrooms, in order to get the best sale price for its clients.  It needs a model that can generate a good estimate of value for homes in every part of the county."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "To build a model to predict  prices, I used data from the King County House Sales dataset, which can be found here:\n",
    "\n",
    "(https://www.kaggle.com/harlfoxem/housesalesprediction)\n",
    "\n",
    "This dataset contains information on over 21,000 houses sold in King County between May, 2014 and May, 2015.  Although the median sale price is \\\\$450,000, the dataset also includes multi-million dollar homes.  At the top of the market are about 1,000 properties which sold between \\\\$1.2 million and \\\\$7.7 million, so the price data are right-skewed with a few very high outliers.\n",
    "\n",
    "In addition to sale price, the dataset includes details about the homes, including square footage, lot square footage, number of bedrooms, zip code, and the dates when the houses were built, renovated, and sold.  Although the data seem mostly accurate, some values are missing, and many columns have outliers.\n",
    "\n",
    "Definitions of all column names are below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Names and Descriptions for King County Data Set\n",
    "\n",
    "* **id** - unique identifier for a house\n",
    "* **date** - house was sold\n",
    "* **price** -  is prediction target\n",
    "* **bedrooms** -  number of bedrooms\n",
    "* **bathrooms** -  number of bathrooms\n",
    "* **sqft_living** -  footage of the home\n",
    "* **sqft_lot** -  footage of the lot\n",
    "* **floors** -  floors (levels) in house\n",
    "* **waterfront** - House which has a view to a waterfront\n",
    "* **view** - Has been viewed\n",
    "* **condition** - How good the condition is ( Overall )\n",
    "* **grade** - overall grade given to the housing unit, based on King County grading system\n",
    "* **sqft_above** - square footage of house apart from basement\n",
    "* **sqft_basement** - square footage of the basement\n",
    "* **yr_built** - Built Year\n",
    "* **yr_renovated** - Year when house was renovated\n",
    "* **zipcode** - zip\n",
    "* **lat** - Latitude coordinate\n",
    "* **long** - Longitude coordinate\n",
    "* **sqft_living15** - The square footage of interior housing living space for the nearest 15 neighbors\n",
    "* **sqft_lot15** - The square footage of the land lots of the nearest 15 neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and Split into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import eli5\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "data = pd.read_csv('data/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into test and training sets\n",
    "\n",
    "# choose relevant columns:\n",
    "\n",
    "X=data.drop(columns=['price'])\n",
    "\n",
    "y=data['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate X_train and y_train back together for initial exploration\n",
    "\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "### Right-Skewed Columns and Outliers\n",
    "\n",
    "While exploring the data, I found several columns that are right skewed, including:\n",
    "* price\n",
    "* bedrooms\n",
    "* bathrooms\n",
    "* sqft_living\n",
    "* sqft_lot\n",
    "* sqft_above\n",
    "* sqft_living15\n",
    "* sqft_lot15\n",
    "\n",
    "In this section, I investigated the right-skewed columns.  I found that although the data do not appear inaccurate, many columns have high outliers.  I removed the highest outliers in price, square footage, and lot square footage from the data to improve the model's accuracy for the remaining homes.  Later, I will use log transformation on some columns to reduce the effect of the skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore training data\n",
    "\n",
    "train_data.head(500)\n",
    "train_data.info()\n",
    "train_data.describe()\n",
    "\n",
    "# questions and observations:\n",
    "# high outliers in price, bedrooms, bathrooms, sqft_living, sqft_lot\n",
    "# null values in waterfront, view, yr_renovated\n",
    "# waterfront has lots of 0s in addition to null values\n",
    "# need to turn date (sale date) into a date\n",
    "# need to turn sqft_basement into a float (but it has some non-number values, like ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data set time frame\n",
    "\n",
    "pd.to_datetime(train_data['date']).describe()\n",
    "\n",
    "# homes sold between May 2014 and May 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate price outliers\n",
    "plt.boxplot(train_data['price'])\n",
    "plt.xlabel('homes')\n",
    "plt.ylabel('price'); # looks like outliers are probably accurate, but may decrease the model's efficacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 95th percentile of price data\n",
    "train_data['price'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at highest price outliers\n",
    "\n",
    "data_price_outliers = train_data.loc[data.price >= 1170000].sort_values(by='price', ascending=False)\n",
    "data_price_outliers.head(500)\n",
    "data_price_outliers.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['price'].hist(bins = 10)\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.xlabel('price')\n",
    "plt.ylabel('number of homes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both the box plot and the histogram above, prices look extremely unusual above $3 million.  There are 36 homes at or above this sale price in the training data.  I will remove these to improve the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many homes sold at or above $3 million?\n",
    "\n",
    "train_data['price'].loc[train_data['price'] >= 3000000].count() #36 homes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with price > $3 million for training data\n",
    "\n",
    "train_data = train_data.loc[train_data['price'] < 3000000]\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the same change to the test data\n",
    "\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data['price'].loc[test_data['price'] >= 3000000].count() #15 homes\n",
    "test_data = test_data.loc[test_data['price'] < 3000000]\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at row detail, max values for bedrooms, bathrooms, sqft_living & sqft_above seem plausible\n",
    "# but for sqft_living and sqft_above, there is one home with a huge outlier\n",
    "# same with sqft_lot\n",
    "\n",
    "# outliers = train_data.sort_values(by='bedrooms', ascending=False).head(500)\n",
    "# outliers = train_data.sort_values(by='bathrooms', ascending=False).head(500)\n",
    "# outliers = train_data.sort_values(by='sqft_living', ascending=False).head(500)\n",
    "# outliers = train_data.sort_values(by='sqft_above', ascending=False).head(500)\n",
    "outliers = train_data.sort_values(by='sqft_lot', ascending=False).head(500)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate sqft_living outliers\n",
    "\n",
    "plt.boxplot(train_data.sqft_living)\n",
    "plt.xlabel('homes')\n",
    "plt.ylabel('sqft_living');\n",
    "\n",
    "# the max value may be accurate, but let's drop it to improve model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop sqft_living > 8000 from training and testing data\n",
    "\n",
    "train_data = train_data.loc[train_data['sqft_living'] <= 8000]\n",
    "test_data = test_data.loc[test_data['sqft_living'] <= 8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate sqft_lot outliers\n",
    "\n",
    "plt.boxplot(train_data.sqft_lot)\n",
    "plt.xlabel('homes')\n",
    "plt.ylabel('sqft_lot');\n",
    "\n",
    "# the max values may be accurate, but let's drop them to improve model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove sqft_lot > 600,000 from train and test data\n",
    "\n",
    "train_data = train_data.loc[train_data['sqft_lot'] <= 600000]\n",
    "test_data = test_data.loc[test_data['sqft_lot'] <= 600000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null values\n",
    "\n",
    "Four columns had null values: 'waterfront', 'yr_renovated', 'sqft_basement', and 'view'.  Since fewer than 1% of properties were marked as having waterfront views, I dropped this column from the analysis.  I replaced 'yr_renovated' with a binary column showing whether or not the home was marked renovated in any year.  I replaced the null values in 'sqft_basement' (which appeared as ? in the data) with zeros, since the median of the non-null values in this column was also zero.  Since 'view' refers to the number of times a house had been viewed (not whether it has a nice view), I dropped this column from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate null values in waterfront\n",
    "\n",
    "train_data.waterfront.value_counts() # binary - 1 or 0\n",
    "train_data.waterfront.isna().sum() #1647 null values out of 21596\n",
    "train_data.waterfront.value_counts() \n",
    "\n",
    "# Only 89 homes are marked as waterfront -- less than 1% of data\n",
    "# So I'll drop this feature from the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# deal with null values in yr_renovated\n",
    "\n",
    "train_data['yr_renovated'].value_counts().head(50)\n",
    "# 11869 values are 0 (meaning no true value)\n",
    "\n",
    "nulls = train_data['yr_renovated'].isna().sum()\n",
    "nulls #2692 values are null\n",
    "\n",
    "# many of the values with years are old, e.g. 1950's-1990's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column showing homes renovated or not\n",
    "train_data['renovated'] = np.where(train_data['yr_renovated'] > 0, 1, 0)\n",
    "train_data['renovated'].value_counts() # only 511 homes show a year renovated\n",
    "\n",
    "# make same change to testing data\n",
    "test_data['renovated'] = np.where(test_data['yr_renovated'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with non-number values in sqft_basement\n",
    "train_data['sqft_basement'].value_counts() # continuous variable, but has many '?' values\n",
    "# also many 0 values.  Not sure if these homes truly do not have basements.\n",
    "\n",
    "# per cent of data that is missing:\n",
    "missing_sqft_basement = round((len(train_data.loc[train_data['sqft_basement'] == '?'])/len(train_data))*100, 2)\n",
    "print(missing_sqft_basement, \"% of basement data is missing\")\n",
    "\n",
    "# per cent of data that is zero:\n",
    "missing_sqft_basement = round((len(train_data.loc[train_data['sqft_basement'] == '0.0'])/len(train_data))*100, 2)\n",
    "print(missing_sqft_basement, \"% of basement data is zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for now, let's fill missing values with zero, since that's the median\n",
    "\n",
    "# replace all '?' values with '0'\n",
    "train_data.loc[train_data['sqft_basement'] == '?', 'sqft_basement'] = '0'\n",
    "\n",
    "# same for test data\n",
    "test_data.loc[test_data['sqft_basement'] == '?', 'sqft_basement'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert sqft_basement values to integers\n",
    "\n",
    "train_data['sqft_basement'] = pd.to_numeric(train_data['sqft_basement'])\n",
    "\n",
    "test_data['sqft_basement'] = pd.to_numeric(test_data['sqft_basement'])\n",
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Correlations\n",
    "\n",
    "The analysis below shows that the strongest correlations with price (the target variable) are sqft_living, sqft_above, sqft_living15, grade, and bathrooms.\n",
    "The strongest correlations between X variables are among these same columns -- all five are correlated with each other.  This multicolinearity could negatively impact a prediction model, so I will experiment with dropping combinations of multicolinear columns later on.\n",
    "Of all the variables, only grade and bedrooms look normally distributed.  Most are right-skewed, including price.  Later, I will see if log transformations on these variables improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore training data\n",
    "# let's try a pairplot to see if anything stands out\n",
    "\n",
    "cols_of_interest = [ \n",
    "                    'bedrooms', \n",
    "                    'bathrooms', \n",
    "                    'sqft_living',\n",
    "                    'sqft_lot', \n",
    "                    'condition', \n",
    "                    'grade', \n",
    "                    'sqft_above',\n",
    "                    'yr_built',  \n",
    "                    'sqft_living15', \n",
    "                    'sqft_lot15',\n",
    "                    'price']\n",
    "\n",
    "sns.pairplot(train_data[cols_of_interest]);\n",
    "\n",
    "# the strongest correlations with price are sqft_living, sqft_above, sqft_living15, grade, and bathrooms\n",
    "# strongest correlations between X variables are among these same columns\n",
    "# only grade and bedrooms look normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's make a heatmap to be sure\n",
    "\n",
    "sns.heatmap(train_data[cols_of_interest].corr())\n",
    "\n",
    "# yes, confirms the observations above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the numbers\n",
    "\n",
    "train_data[cols_of_interest].corr()\n",
    "\n",
    "# sqft_living is the best predictor of price so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look just at the correlations with price\n",
    "\n",
    "train_data[cols_of_interest].corr()['price'].sort_values(ascending=False)\n",
    "\n",
    "# interesting, sqft_living and grade are far above the rest\n",
    "# grade is probably based in part on sqft_living"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Exclusion\n",
    "Based on the analyses above, I decided to exclude the following columns from the model.  Justifications are provided below:\n",
    "\n",
    "* id - the randomly assigned house id\n",
    "* date - date sold, all are between May 2014 and May 2015.  May investigate impact of month later\n",
    "* waterfront - less than 1% of homes marked as waterfront\n",
    "* view - number of times the home has been viewed - not relevant for pricing homes newly on the market\n",
    "* yr_renovated - missing values.  Turned into binary column 'renovated'\n",
    "* 'lat' and 'long' - latitude and longitude of house - easier to pull location info with zipcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I tested nine models, and selected Model 8 as the most effective.  \\\n",
    "\\\n",
    "I first calculated a model-less baseline with an R-squared of 0 and a Mean Absolute Error of \\\\$227K.  I then tested a baseline linear regression model without transforming any features of the data.  This produced an R-squared of 0.64 and 0.62 for the training and test sets respectively, and Mean Absolute Errors of \\\\$135K and \\\\$136K respectively. \\\n",
    "\\\n",
    "After experimenting with log-transforming the X variables and the target variable price, I was able to improve the metrics by log-transforming price, sqft_living15, and sqft_lot15.  By assigning zip codes to price-based classifications, I improved the R-squared to 0.83 for both the training and test data, with Mean Absolute Errors of \\\\$88K and \\\\$87K respectively. \\\n",
    "\\\n",
    "I also tested other strategies, such as reducing multicolinearity by dropping columns, omitting features with high p-values, and assigning the yr_built data to categories.  None of these changes improved the model.  However, omitting features with high p-values did not reduce the model's effectiveness either, so I kept this change in order to simplify the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the preprocessed training and test sets back into X and y\n",
    "\n",
    "# choose relevant columns:\n",
    "\n",
    "X_train=train_data[['bedrooms', \n",
    "       'bathrooms', \n",
    "       'sqft_living', \n",
    "       'sqft_lot', \n",
    "       'floors', \n",
    "       'condition', \n",
    "       'grade',\n",
    "       'sqft_above', \n",
    "       'sqft_basement', \n",
    "       'yr_built', \n",
    "       'zipcode',\n",
    "       'sqft_living15', \n",
    "       'sqft_lot15', \n",
    "       'renovated']]\n",
    "\n",
    "y_train=train_data['price']\n",
    "\n",
    "X_test=test_data[['bedrooms', \n",
    "       'bathrooms', \n",
    "       'sqft_living', \n",
    "       'sqft_lot', \n",
    "       'floors', \n",
    "       'condition', \n",
    "       'grade',\n",
    "       'sqft_above', \n",
    "       'sqft_basement', \n",
    "       'yr_built', \n",
    "       'zipcode',\n",
    "       'sqft_living15', \n",
    "       'sqft_lot15', \n",
    "       'renovated']]\n",
    "\n",
    "y_test=test_data['price']\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Model-less Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for our first model-less baseline, let's use the mean price\n",
    "# start with training set\n",
    "\n",
    "mean_price = y_train.mean()\n",
    "y_pred_train = np.full(shape=(len(X_train), 1), fill_value=mean_price)\n",
    "\n",
    "# check r2\n",
    "r2_baseline_train = round(r2_score(y_true=y_train, y_pred=y_pred_train), 6)\n",
    "\n",
    "# check Mean Absolute Error\n",
    "mae_baseline_train = round(mean_absolute_error(y_true=y_train, y_pred=y_pred_train), 2)\n",
    "\n",
    "# check Root Mean Squared Error\n",
    "rmse_baseline_train = round(np.sqrt(mean_squared_error(y_true=y_train, y_pred=y_pred_train)), 2)\n",
    "\n",
    "print('Training Data', '\\n', \n",
    "      'Mean Price:', round(mean_price, 2), '\\n', \n",
    "      'R-Squared:', r2_baseline_train, '\\n',\n",
    "      'Mean Absolute Error:', mae_baseline_train, '\\n',\n",
    "      'Root Mean Squared Error:', rmse_baseline_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's calculate baseline r2, MAE, and RMSE for the test set\n",
    "\n",
    "y_pred_test = np.full(shape=(len(X_test), 1), fill_value=mean_price)\n",
    "\n",
    "r2_baseline_test = round(r2_score(y_true=y_test, y_pred=y_pred_test), 6)\n",
    "mae_baseline_test = round(mean_absolute_error(y_true=y_test, y_pred=y_pred_test), 2)\n",
    "rmse_baseline_test = round(np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred_test)), 2)\n",
    "\n",
    "print('Testing Data', '\\n', \n",
    "      'Mean Price:', round(mean_price, 2), '\\n', \n",
    "      'R-Squared:', r2_baseline_test, '\\n',\n",
    "      'Mean Absolute Error:', mae_baseline_test, '\\n',\n",
    "      'Root Mean Squared Error:', rmse_baseline_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for evaluating models:\n",
    "\n",
    "def evaluate_model(y_train, y_train_pred, y_test, y_test_pred):\n",
    "    \n",
    "    \"\"\"Calculate evaluation metrics for the model: R-Squared, Mean Absolute Error, and Root Mean Squared Error\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_train: Series of true values from the training set target variable\n",
    "    y_train_pred: Series of target variable values predicted by the model for the training set\n",
    "    y_test: Series of true values from the test set target variable\n",
    "    y_test_pred: Series of target variable values predicted by the model for the test set\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Print of metrics for training and test sets\"\"\"\n",
    "\n",
    "    # check train r2\n",
    "    r2_train = round(r2_score(y_true=y_train, y_pred=y_train_pred), 6)\n",
    "\n",
    "    # check train Mean Absolute Error\n",
    "    mae_train = round(mean_absolute_error(y_true=y_train, y_pred=y_train_pred), 2)\n",
    "\n",
    "    # check train Root Mean Squared Error\n",
    "    rmse_train = round(np.sqrt(mean_squared_error(y_true=y_train, y_pred=y_train_pred)), 2)\n",
    "\n",
    "    print('Training Data', '\\n', \n",
    "          'R-Squared:', r2_train, '\\n',\n",
    "          'Mean Absolute Error:', mae_train, '\\n',\n",
    "          'Root Mean Squared Error:', rmse_train, '\\n')\n",
    "    \n",
    "    # check test r2\n",
    "    r2_test = round(r2_score(y_true=y_test, y_pred=y_test_pred), 6)\n",
    "\n",
    "    # check test Mean Absolute Error\n",
    "    mae_test = round(mean_absolute_error(y_true=y_test, y_pred=y_test_pred), 2)\n",
    "\n",
    "    # check train Root Mean Squared Error\n",
    "    rmse_test = round(np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_test_pred)), 2)\n",
    "\n",
    "    print('Testing Data', '\\n', \n",
    "          'R-Squared:', r2_test, '\\n',\n",
    "          'Mean Absolute Error:', mae_test, '\\n',\n",
    "          'Root Mean Squared Error:', rmse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean is not a good predictor of price!\n",
    "\n",
    "# let's fit a baseline regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Baseline Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's scale the data so we can evaluate the coefficients of the baseline model\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do a linear regression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred2 = linreg.predict(X_train_scaled)\n",
    "y_test_pred2 = linreg.predict(X_test_scaled)\n",
    "\n",
    "evaluate_model(y_train, y_train_pred2, y_test, y_test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's better, but the model still only explains about 60% of the variance\n",
    "# store as 'best_r2' for comparison\n",
    "\n",
    "best_r2 = {'train': 0.635164, 'test': 0.618171}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's plot training set residuals\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize = (18,6))\n",
    "\n",
    "residuals_train = y_train-y_train_pred2\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.scatter(y_train_pred2, residuals_train)\n",
    "ax1.plot(y_train_pred2, [0 for i in range(len(y_train_pred2))])\n",
    "plt.title('Training Data')\n",
    "plt.xlabel('price predictions')\n",
    "plt.ylabel('error')\n",
    "\n",
    "residuals_test = y_test-y_test_pred2\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.scatter(y_test_pred2, residuals_test)\n",
    "ax2.plot(y_test_pred2, [0 for i in range(len(y_test_pred2))])\n",
    "plt.title('Test Data')\n",
    "plt.xlabel('price predictions')\n",
    "plt.ylabel('error');\n",
    "\n",
    "# cone-shaped residuals indicate heteroskedasticity\n",
    "# means that as price increases, error increases as well\n",
    "# will try log transformations to reduce the effect of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it in Statsmodels to check coefficients\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)))\n",
    "results = model.fit()\n",
    "\n",
    "results.summary()\n",
    "\n",
    "# same R-squared as above\n",
    "# sqft_lot and sqft_above have p-values above 0.05.  Experiment with removing these later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: 7 Log-Transformed X Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's look at the numeric variables.  Are they normally distributed?\n",
    "\n",
    "numeric = ['bedrooms', \n",
    "       'bathrooms', \n",
    "       'sqft_living', \n",
    "       'sqft_lot', \n",
    "       'floors', \n",
    "       'condition', \n",
    "       'grade',\n",
    "       'sqft_above', \n",
    "       'sqft_basement', \n",
    "       'yr_built',\n",
    "       'sqft_living15', \n",
    "       'sqft_lot15'\n",
    "             ]\n",
    "\n",
    "num_cols = 3\n",
    "if len(numeric)%num_cols == 0:\n",
    "    num_rows = len(numeric)//num_cols\n",
    "else:\n",
    "    num_rows = (len(numeric)//num_cols)+1\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12,20), nrows=num_rows, ncols=num_cols)\n",
    "\n",
    "\n",
    "for feat in numeric:\n",
    "    axs[numeric.index(feat)//num_cols, numeric.index(feat)%num_cols].hist(X_train[feat], bins=20)\n",
    "    axs[numeric.index(feat)//num_cols, numeric.index(feat)%num_cols].set_title(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric variables are not normally distributed\n",
    "# let's try to log these and see if they become more normal\n",
    "# don't include features with zeros, like sqft_basement\n",
    "\n",
    "non_zero = ['bedrooms', \n",
    "       'bathrooms', \n",
    "       'sqft_living', \n",
    "       'sqft_lot', \n",
    "       'floors', \n",
    "       'condition', \n",
    "       'grade',\n",
    "       'sqft_above', \n",
    "       'yr_built',\n",
    "       'sqft_living15', \n",
    "       'sqft_lot15'\n",
    "             ]\n",
    "\n",
    "X_train_logged = X_train.copy()\n",
    "\n",
    "for feat in non_zero:\n",
    "    X_train_logged[feat] = X_train_logged[feat].map(lambda x: np.log(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Did it help?  Make more histograms\n",
    "\n",
    "num_cols = 3\n",
    "if len(non_zero)%num_cols == 0:\n",
    "    num_rows = len(non_zero)//num_cols\n",
    "else:\n",
    "    num_rows = (len(non_zero)//num_cols)+1\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12,20), nrows=num_rows, ncols=num_cols)\n",
    "\n",
    "\n",
    "for feat in non_zero:\n",
    "    axs[non_zero.index(feat)//num_cols, non_zero.index(feat)%num_cols].hist(X_train_logged[feat], bins=20)\n",
    "    axs[non_zero.index(feat)//num_cols, non_zero.index(feat)%num_cols].set_title(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it helped - some variables look more normally distributed\n",
    "# like sqft_living, sqft_lot, grade, sqft_above, sqft_living15, sqft_lot15\n",
    "# and to a lesser extent, bedrooms and grade too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we build a model with just the above columns logged\n",
    "\n",
    "# build a new X_train with just the above features logged\n",
    "\n",
    "to_log = ['bedrooms', \n",
    "       'sqft_living', \n",
    "       'sqft_lot', \n",
    "       'grade',\n",
    "       'sqft_above', \n",
    "       'sqft_living15', \n",
    "       'sqft_lot15'\n",
    "             ]\n",
    "\n",
    "X_train3 = X_train.copy()\n",
    "\n",
    "for feat in to_log:\n",
    "    X_train3[feat] = X_train3[feat].map(lambda x: np.log(x))\n",
    "    \n",
    "# log the test data\n",
    "\n",
    "X_test3 = X_test.copy()\n",
    "\n",
    "for feat in to_log:\n",
    "    X_test3[feat] = X_test3[feat].map(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a function to scale the X variables, and do a linear regression\n",
    "\n",
    "def scale_lin_reg(X_train, y_train, X_test):\n",
    "    \n",
    "    \"\"\"Perform standard scaling and linear regression given training set and test set X-variables\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: DataFrame of training set input variables\n",
    "    y_train: Array of true values from the training set target variable\n",
    "    X_test: DataFrame of test set input variables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_train_pred: Series of training set target variable predictions\n",
    "    y_test_pred: Series of test set target variable predictions \n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_train_pred = linreg.predict(X_train_scaled)\n",
    "    y_test_pred = linreg.predict(X_test_scaled)\n",
    "        \n",
    "    return(y_train_pred, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scale and do a linear regression on the transformed data, to return y_train_pred and y_test_pred\n",
    "# the inputs X_train3 and X_test3 have 7 features logged\n",
    "\n",
    "y_train_pred3, y_test_pred3 = scale_lin_reg(X_train=X_train3, y_train=y_train, X_test=X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's evaluate that model\n",
    "evaluate_model(y_train=y_train, y_train_pred=y_train_pred3, y_test=y_test, y_test_pred=y_test_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_r2\n",
    "\n",
    "# oh no!  It didn't help!  R2 got worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: 2 Logged X Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these two features have the most improvement in normality after log transformations:\n",
    "# sqft_living15\n",
    "# sqft_lot15\n",
    "\n",
    "# what if we just log these?\n",
    "\n",
    "to_log = [\n",
    "       'sqft_living15', \n",
    "       'sqft_lot15'\n",
    "             ]\n",
    "\n",
    "X_train4 = X_train.copy()\n",
    "\n",
    "for feat in to_log:\n",
    "    X_train4[feat] = X_train4[feat].map(lambda x: np.log(x))\n",
    "\n",
    "# log the test data\n",
    "\n",
    "X_test4 = X_test.copy()\n",
    "\n",
    "for feat in to_log:\n",
    "    X_test4[feat] = X_test4[feat].map(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scale and do a linear regression on the transformed data, to return y_train_pred and y_test_pred\n",
    "# the inputs X_train4 and X_test4 have 2 features logged\n",
    "\n",
    "y_train_pred4, y_test_pred4 = scale_lin_reg(X_train=X_train4, y_train=y_train, X_test=X_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "evaluate_model(y_train=y_train, y_train_pred=y_train_pred4, y_test=y_test, y_test_pred=y_test_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_r2\n",
    "\n",
    "# That is a very slight improvement over the baseline model\n",
    "# Price (target variable) was also right-skewed.  Let's try logging this as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Two Logged X Variables and Logged Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_logged = y_train.copy()\n",
    "y_train_logged = y_train_logged.map(lambda y: np.log1p(y))\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15,4), nrows=1, ncols=2)\n",
    "\n",
    "ax[0].hist(y_train, bins=20)\n",
    "ax[0].set_title('y_train')\n",
    "\n",
    "ax[1].hist(y_train_logged, bins=20)\n",
    "ax[1].set_title('y_train_logged');\n",
    "\n",
    "# the logged y_train definitely looks more normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log y_test as well\n",
    "\n",
    "y_test_logged = y_test.copy()\n",
    "y_test_logged = y_test_logged.map(lambda y: np.log1p(y))\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15,4), nrows=1, ncols=2)\n",
    "\n",
    "ax[0].hist(y_test, bins=20)\n",
    "ax[0].set_title('y_test')\n",
    "\n",
    "ax[1].hist(y_test_logged, bins=20)\n",
    "ax[1].set_title('y_test_logged');\n",
    "\n",
    "# the logged y_test looks more normally distributed too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's run and evaluate the model with X_train4, X_test4, y_train_logged and y_test_logged\n",
    "\n",
    "y_train_pred5, y_test_pred5 = scale_lin_reg(X_train=X_train4, y_train=y_train_logged, X_test=X_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to only evaluate R-squared, since MAE and RMSE must use unlogged price predictions\n",
    "\n",
    "def eval_r2(y_train, y_train_pred, y_test, y_test_pred):\n",
    "    \"\"\"Evalute R-Squared for training and test predictions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_train: Array of true values from the training set target variable\n",
    "    y_train_pred: Array of target variable values predicted by the model for the training set\n",
    "    y_test: Array of true values from the test set target variable\n",
    "    y_test_pred: Array of target variable values predicted by the model for the test set\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Print of R-Squared for training and test sets\"\"\"\n",
    "\n",
    "    # calculate r2 using logged target variable\n",
    "    r2_train = round(r2_score(y_true=y_train, y_pred=y_train_pred), 6)\n",
    "    r2_test = round(r2_score(y_true=y_test, y_pred=y_test_pred), 6)\n",
    "\n",
    "    print('Training Data', '\\n', \n",
    "          'R-Squared:', r2_train, '\\n')\n",
    "    \n",
    "    print('Test Data', '\\n', \n",
    "          'R-Squared:', r2_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_r2(y_train=y_train_logged, y_train_pred=y_train_pred5, y_test=y_test_logged, y_test_pred=y_test_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# great, it helped a little, but need to unlog y_train_pred5 and y_test_pred5 to measure price errors\n",
    "\n",
    "# create a function to unlog predictions and measure MAE and RMSE\n",
    "def unlog_MAE_RMSE(y_train, y_train_logged_pred, y_test, y_test_logged_pred):\n",
    "    \n",
    "    \"\"\"Unlog target variable values, and evaluate Mean Absolute Error and Root Mean Squared Error for training and test predictions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_train: Series of true values from the training set target variable\n",
    "    y_train_logged_pred: Series of target variable values predicted using a logged target variable; training set\n",
    "    y_test: Series of true values from the test set target variable\n",
    "    y_test_pred: Series of target variable values predicted using a logged target variable; test set\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Print of Mean Absolute Error and Root Mean Squared Error for training and test sets\"\"\"\n",
    "    \n",
    "    # unlog target variable predictions to measure MAE and RMSE\n",
    "    y_train_pred_exp = np.expm1(y_train_logged_pred)\n",
    "    y_test_pred_exp = np.expm1(y_test_logged_pred)\n",
    "    \n",
    "    # check Mean Absolute Error\n",
    "    mae_train = round(mean_absolute_error(y_true=y_train, y_pred=y_train_pred_exp), 2)\n",
    "    mae_test = round(mean_absolute_error(y_true=y_test, y_pred=y_test_pred_exp), 2)\n",
    "\n",
    "    # check Root Mean Squared Error\n",
    "    rmse_train = round(np.sqrt(mean_squared_error(y_true=y_train, y_pred=y_train_pred_exp)), 2)\n",
    "    rmse_test = round(np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_test_pred_exp)), 2)\n",
    "\n",
    "    print('Training Data', '\\n', \n",
    "          'Mean Absolute Error:', mae_train, '\\n',\n",
    "          'Root Mean Squared Error:', rmse_train, '\\n')\n",
    "    \n",
    "    print('Test Data', '\\n', \n",
    "          'Mean Absolute Error:', mae_test, '\\n',\n",
    "          'Root Mean Squared Error:', rmse_test, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlog_MAE_RMSE(y_train=y_train, y_train_logged_pred=y_train_pred5, y_test=y_test, y_test_logged_pred=y_test_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update best_r2\n",
    "\n",
    "best_r2['train'] = 0.656332\n",
    "best_r2['test'] = 0.62867"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: Two Logged X Variables, Logged Target Variable, and Zip Code Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to assign zip codes to price categories\n",
    "\n",
    "X_train6 = X_train4.copy() # use X_train4, which had two features logged\n",
    "\n",
    "X_train6.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train6['zipcode'].value_counts().count() # 70 different zips\n",
    "X_train6['zipcode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips=pd.concat([X_train6['zipcode'], pd.DataFrame(y_train)['price']], axis=1)\n",
    "zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find mean price by zip to see if any stand out\n",
    "\n",
    "zips_pivot = zips.pivot_table(values='price', index='zipcode', ).sort_values(by='price', ascending=False)\n",
    "zips_pivot.plot(kind='bar', figsize=(16,10))\n",
    "plt.ylabel('mean house price')\n",
    "plt.legend;\n",
    "\n",
    "plt.savefig('price_by_zip_code')\n",
    "\n",
    "# yes, some do stand out!  the top four, the bottom three\n",
    "# what if I classified them based on price? I can make a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary of zip codes and classifications\n",
    "\n",
    "ordered_zip_list = list(zips_pivot.index)\n",
    "zip_dict = {}\n",
    "\n",
    "# display all zips and index in price-ordered list for eyeballing\n",
    "\n",
    "for i in ordered_zip_list:\n",
    "    print(i, ordered_zip_list.index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classify zips in dict:\n",
    "\n",
    "zip_dict[ordered_zip_list[0]] = 'Zip Class 1'\n",
    "\n",
    "# make a function to add entries more easily\n",
    "def add_to_zip_dict(list_index_start, list_index_stop, category):\n",
    "    \n",
    "    \"\"\"Add entries to zip_dict based on their index in ordered_zip_list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_index_start: index in ordered_zip_list of the first zip code to enter\n",
    "    list_index_stop: index in ordered_zip_list of the zip code to stop at\n",
    "    category: zip class to assign to these entries\"\"\"\n",
    "    \n",
    "    for i in ordered_zip_list[list_index_start:list_index_stop]:\n",
    "        zip_dict[i] = category\n",
    "\n",
    "add_to_zip_dict(1, 4, 'Zip Class 2')\n",
    "add_to_zip_dict(4, 13, 'Zip Class 3')\n",
    "add_to_zip_dict(13, 34, 'Zip Class 4')\n",
    "add_to_zip_dict(34, 49, 'Zip Class 5')\n",
    "add_to_zip_dict(49, 67, 'Zip Class 6')\n",
    "add_to_zip_dict(67, 70, 'Zip Class 7')\n",
    "\n",
    "zip_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add classification column to training data\n",
    "\n",
    "X_train6['zip_class'] = X_train6['zipcode'].map(lambda x: zip_dict[x])\n",
    "X_train6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode classification column and drop zipcode and zip_class columns\n",
    "\n",
    "zip_class_columns = pd.get_dummies(X_train6['zip_class'], drop_first=True)\n",
    "zip_class_columns\n",
    "\n",
    "X_train6 = pd.concat([X_train6, zip_class_columns], axis=1)\n",
    "X_train6.drop(columns=['zipcode','zip_class'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add same features to test set\n",
    "\n",
    "X_test6 = X_test4\n",
    "X_test6['zip_class'] = X_test6['zipcode'].map(lambda x: zip_dict[x])\n",
    "\n",
    "zip_class_columns = pd.get_dummies(X_test6['zip_class'], drop_first=True)\n",
    "X_test6 = pd.concat([X_test6, zip_class_columns], axis=1)\n",
    "X_test6.drop(columns=['zipcode','zip_class'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train6 #looks good\n",
    "X_test6 #looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "\n",
    "y_train_pred6, y_test_pred6 = scale_lin_reg(X_train=X_train6, y_train=y_train_logged, X_test=X_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model using R-squared\n",
    "\n",
    "eval_r2(y_train=y_train_logged, y_train_pred=y_train_pred6, y_test=y_test_logged, y_test_pred=y_test_pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate MAE and RMSE, unlog y_train_pred6 and y_test_pred6\n",
    "\n",
    "unlog_MAE_RMSE(y_train=y_train, y_train_logged_pred=y_train_pred6, y_test=y_test, y_test_logged_pred=y_test_pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# great, this really helped!\n",
    "# update best_r2\n",
    "\n",
    "best_r2 = {'train': 0.831058, 'test': 0.825734}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the training set residuals:\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,6))\n",
    "\n",
    "residuals_train6 = y_train_logged-y_train_pred6\n",
    "ax1 = plt.subplot(121)\n",
    "plt.scatter(y_train_pred6, residuals_train6)\n",
    "plt.plot(y_train_pred6, [0 for i in range(len(y_train_pred6))])\n",
    "plt.title('Training Data')\n",
    "plt.xlabel('logged price predictions')\n",
    "plt.ylabel('error')\n",
    "\n",
    "residuals_test6 = y_test_logged-y_test_pred6\n",
    "ax2 = plt.subplot(122)\n",
    "plt.scatter(y_test_pred6, residuals_test6)\n",
    "plt.plot(y_test_pred6, [0 for i in range(len(y_test_pred6))])\n",
    "plt.title('Test Data')\n",
    "plt.xlabel('logged price predictions')\n",
    "plt.ylabel('error');\n",
    "\n",
    "# looks better than the cone shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at coefficients\n",
    "\n",
    "model = sm.OLS(y_train_logged, sm.add_constant(pd.DataFrame(X_train6, columns=X_train6.columns, index=X_train6.index)))\n",
    "results = model.fit()\n",
    "\n",
    "results.summary()\n",
    "\n",
    "# sqft_above and sqft_basement have high p-values\n",
    "# experiment with removing these later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which variables are most closely correlated with price?\n",
    "X_train6.corrwith(y_train_logged).sort_values(ascending=False)\n",
    "\n",
    "# grade and sqft_living, as in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot variables that are closely correlated with price, for presentation to non-technical stakeholders\n",
    "\n",
    "plt.subplots(figsize=(15,12));\n",
    "\n",
    "ax1 = plt.subplot(221)\n",
    "sns.regplot(X_train6['sqft_living'], y_train_logged, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Training Data')\n",
    "plt.ylabel('logged price')\n",
    "\n",
    "ax2 = plt.subplot(222)\n",
    "sns.regplot(X_test6['sqft_living'], y_test_logged, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Test Data')\n",
    "plt.ylabel('logged price')\n",
    "\n",
    "ax3 = plt.subplot(223)\n",
    "sns.regplot(X_train6['sqft_living'], y_train, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Training Data')\n",
    "\n",
    "ax4 = plt.subplot(224)\n",
    "sns.regplot(X_test6['sqft_living'], y_test, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Test Data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,12));\n",
    "\n",
    "ax1 = plt.subplot(221)\n",
    "sns.regplot(X_train6['grade'], y_train_logged, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Training Data')\n",
    "plt.ylabel('logged price')\n",
    "\n",
    "ax2 = plt.subplot(222)\n",
    "sns.regplot(X_test6['grade'], y_test_logged, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Test Data')\n",
    "plt.ylabel('logged price')\n",
    "\n",
    "ax3 = plt.subplot(223)\n",
    "sns.regplot(X_train6['grade'], y_train, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Training Data')\n",
    "\n",
    "ax4 = plt.subplot(224)\n",
    "sns.regplot(X_test6['grade'], y_test, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Test Data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,12));\n",
    "\n",
    "ax1 = plt.subplot(221)\n",
    "sns.regplot(X_train6['sqft_living15'], y_train_logged, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Training Data')\n",
    "plt.xlabel('logged square footage of 15 nearest neighbors')\n",
    "plt.ylabel('logged price')\n",
    "\n",
    "ax2 = plt.subplot(222)\n",
    "sns.regplot(X_test6['sqft_living15'], y_test_logged, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Test Data')\n",
    "plt.xlabel('logged square footage of 15 nearest neighbors')\n",
    "plt.ylabel('logged price')\n",
    "\n",
    "ax3 = plt.subplot(223)\n",
    "sns.regplot(np.expm1(X_train6['sqft_living15']), y_train, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Training Data')\n",
    "plt.xlabel('square footage of 15 nearest neighbors')\n",
    "\n",
    "ax4 = plt.subplot(224)\n",
    "sns.regplot(np.expm1(X_test6['sqft_living15']), y_test, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Test Data')\n",
    "plt.xlabel('square footage of 15 nearest neighbors');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save figures for presentation\n",
    "\n",
    "plt.subplots(figsize=(15,6));\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "sns.regplot(X_train6['sqft_living'], y_train, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Square Footage vs Price', fontsize=20)\n",
    "plt.xlabel('Living Space Square Footage', fontsize=16)\n",
    "plt.ylabel('Home Price in Dollars', fontsize=16)\n",
    "\n",
    "ax3 = plt.subplot(122)\n",
    "sns.regplot(np.expm1(X_train6['sqft_living15']), y_train, line_kws={\"color\": \"blue\"})\n",
    "plt.title('Square Footage of 15 Closest Neighbors vs Price', fontsize=20)\n",
    "plt.xlabel('Square Footage of 15 Nearest Neighbors', fontsize=16)\n",
    "plt.ylabel('Home Price in Dollars', fontsize=16)\n",
    "\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "\n",
    "plt.savefig('images/regplots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7: Testing Removing Multicolinear Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see if removing multicolinearity helps\n",
    "# find top correlations\n",
    "# code from Flatiron Data Science course's Multicollinearity Lab\n",
    "\n",
    "df=X_train6.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "# zip the variable name columns\n",
    "df['pairs'] = list(zip(df.level_0, df.level_1))\n",
    "\n",
    "# set index to pairs\n",
    "df.set_index(['pairs'], inplace = True)\n",
    "\n",
    "#d rop level columns\n",
    "df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# rename correlation column as cc rather than 0\n",
    "df.columns = ['cc']\n",
    "\n",
    "# drop duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.cc>.75) & (df.cc <1)]\n",
    "\n",
    "# high correlations among these four variables:\n",
    "# sqft_living, sqft_above, grade, bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# iterate thru combinations of highly correlated variables to see if dropping them increases r2\n",
    "\n",
    "correlated = ['sqft_living',\n",
    "              'sqft_above',\n",
    "              'grade',\n",
    "              'bathrooms']\n",
    "\n",
    "combs_list=[]\n",
    "\n",
    "for n in range(1,4):\n",
    "    \n",
    "    comb = combinations(correlated,n)\n",
    "    combs_list = combs_list + list(comb)\n",
    "    \n",
    "combs_list\n",
    "\n",
    "for c in combs_list: \n",
    "    print(c)\n",
    "    X_train7 = X_train6.drop(columns = list(c))\n",
    "    X_test7 = X_test6.drop(columns = list(c))\n",
    "    y_train_pred7, y_test_pred7 = scale_lin_reg(X_train=X_train7, y_train=y_train_logged, X_test=X_test7)\n",
    "    eval_r2(y_train=y_train_logged, y_train_pred=y_train_pred7, y_test=y_test_logged, y_test_pred=y_test_pred7)\n",
    "    print('\\n')\n",
    "\n",
    "# despite the multicolinearity, dropping combinations of these columns does not result in an improved R2\n",
    "# dropping sqft_above returns almost exactly the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 8: Test removing features with high p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# according to the statsmodels output, p-values for sqft_above and sqft_basement were above 0.05\n",
    "\n",
    "X_train8 = X_train6.copy()\n",
    "X_train8.drop(columns=['sqft_above', 'sqft_basement'], inplace=True)\n",
    "\n",
    "X_test8 = X_test6.copy()\n",
    "X_test8.drop(columns=['sqft_above', 'sqft_basement'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred8, y_test_pred8 = scale_lin_reg(X_train=X_train8, y_train=y_train_logged, X_test=X_test8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_r2(y_train=y_train_logged, y_train_pred=y_train_pred8, y_test=y_test_logged, y_test_pred=y_test_pred8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlog_MAE_RMSE(y_train=y_train, y_train_logged_pred=y_train_pred8, y_test=y_test, y_test_logged_pred=y_test_pred8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_r2\n",
    "# no improvement in r2 for Model 8, but let's keep this model since at least it reduces multicolinearity\n",
    "# and removes coefficients with high p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at coefficients for Model 8\n",
    "\n",
    "model = sm.OLS(y_train_logged, sm.add_constant(pd.DataFrame(X_train8, columns=X_train8.columns, index=X_train8.index)))\n",
    "results = model.fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 9: Experiment with categorizing year built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made a df to add price back to X variables table, so we can make a pivot table\n",
    "built_df = pd.concat([X_train8, y_train], axis=1)\n",
    "built_pivot = built_df.pivot_table(values='price', index='yr_built', ).sort_values(by='yr_built')\n",
    "\n",
    "# plot a bar graph to look at possible categories\n",
    "built_pivot.plot(kind='bar', figsize=(16,9))\n",
    "plt.ylabel('mean house price')\n",
    "plt.legend;\n",
    "\n",
    "built_df\n",
    "\n",
    "# hmmm, almost looks like older homes and new homes are highly valued, while homes in the middle are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of years, showing the corresponding categories\n",
    "\n",
    "years_list = list(built_pivot.index)\n",
    "years_dict = {}\n",
    "\n",
    "for i in years_list[0:41]:\n",
    "    years_dict[i] = 'pre-war'\n",
    "    \n",
    "for i in years_list[41:88]:\n",
    "    years_dict[i] = 'mid-century'\n",
    "\n",
    "for i in years_list[88:117]:\n",
    "    years_dict[i] = 'recent'\n",
    "    \n",
    "years_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column with yr_built categories\n",
    "\n",
    "built_df['built_cat'] = built_df['yr_built'].map(lambda x: years_dict[x])\n",
    "built_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode classification column\n",
    "\n",
    "built_cat_columns = pd.get_dummies(built_df['built_cat'], drop_first=True)\n",
    "built_cat_columns\n",
    "\n",
    "built_df = pd.concat([built_df, built_cat_columns], axis=1)\n",
    "built_df.drop(columns=['yr_built','built_cat'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "built_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we just have to stick these columns back onto the training and test sets\n",
    "\n",
    "#training set first\n",
    "X_train9 = X_train8.copy()\n",
    "\n",
    "columns_to_add = built_df[['pre-war', 'recent']]\n",
    "X_train9 = pd.concat([X_train9, columns_to_add], axis=1)\n",
    "X_train9.drop(columns='yr_built', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do test set\n",
    "\n",
    "X_test9 = X_test8.copy()\n",
    "\n",
    "X_test9['built_cat'] = X_test9['yr_built'].map(lambda x: years_dict[x])\n",
    "built_cat_columns = pd.get_dummies(X_test9['built_cat'], drop_first=True)\n",
    "\n",
    "X_test9 = pd.concat([X_test9, built_cat_columns], axis=1)\n",
    "X_test9.drop(columns=['yr_built','built_cat'], inplace=True)\n",
    "\n",
    "X_test9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test model 9!\n",
    "\n",
    "y_train_pred9, y_test_pred9 = scale_lin_reg(X_train=X_train9, y_train=y_train_logged, X_test=X_test9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_r2(y_train=y_train_logged, y_train_pred=y_train_pred9, y_test=y_test_logged, y_test_pred=y_test_pred9)\n",
    "\n",
    "# R-squared is less than for Model 8\n",
    "# so, segmenting year_built into categories does not help explain any variance\n",
    "# perhaps this variance can be explained by square footage and location alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train_logged, sm.add_constant(pd.DataFrame(X_train9, columns=X_train9.columns, index=X_train9.index)))\n",
    "results = model.fit()\n",
    "\n",
    "results.summary()\n",
    "# interesting, now floors has the highest p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Future Work\n",
    "\n",
    "To accurately price homes in King County, the real estate firm should use a model that segments zip codes into price-based categories, such as Model 8.  This model combines data about house features that are highly correlated with price, such as square footage, with knowledge of the mean house price of each zip code, to produce predictions that explain 83% of the variance from the mean price.  Model 8 is a significant improvement over the baseline regression model, which only explains 63% of the variance.  In addition, while the baseline regression model's predictions were an average of \\\\$136K off from the actual prices of the test data, Model 8's Mean Absolute Error was only $87K for the test data. \\\n",
    "\\\n",
    "Square footage and grade have the strongest positive correlation with price, but the model vastly improved after zip code classifications were included.  Unsurprisingly, location seems extremely important to home buyers in the Seattle area, which is a diverse landscape that includes, urban, suburban, and rural neighborhoods. \\\n",
    "\\\n",
    "Much work remains to investigate potential improvements to this model.  In particular, including interactions among X variables may increase the model's accuracy.  Since square footage and zip code are such powerful predictors of price, perhaps an interaction between these variables would enhance the model.  Also, since zip code classification was so effective in improving the model, perhaps including a few more zip classes would help by segmenting the market even further.  \n",
    "\n",
    "In addition, the month when the house was sold may affect price, and was not tested in these models.  Also not tested was a feature that would indicate whether the house was recently renovated, for example in the past 20 years.  It may also help to programmatically iterate through the X-variables to select the best features for inclusion in the model.\n",
    "\n",
    "Finally, a handful of properties (less than half of one per cent) must be excluded from this model.  Creating models that can generate predictions for these homes as well would benefit the real estate firm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
